NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-d1b6c9f5-2fca-cc52-dfc9-c080dbd39f28,GPU-0a94f5ff-5681-0311-7df5-87b4c308ca95,GPU-d47aea79-b029-552f-addd-c9d6b4ac89a7,GPU-f5c55947-7ce9-2373-03fd-936f53f0b4b1
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-769745940
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
PDSH_RCMD_TYPE=ssh
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=3db4ece6-fe3f-499b-947e-5bb465738917
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=6p17d6XK-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Voluptuous-Dolore-Zy-Saisir-Ecke-Bedivere
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-4bbdc1cbe9.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=sub3,main1,sub1,sub2
BACKENDAI_SESSION_ID=da65926f-4510-4db9-a83f-aadcc30a1c79
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/usr/local/cuda-12.3/bin:/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/usr/local/cuda-12.3/bin:/usr/local/cuda-12.3/bin:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-c1e78f4a-a764-4e84-861a-e92b47cc6c84.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-d1b6c9f5-2fca-cc52-dfc9-c080dbd39f28,GPU-0a94f5ff-5681-0311-7df5-87b4c308ca95,GPU-d47aea79-b029-552f-addd-c9d6b4ac89a7,GPU-f5c55947-7ce9-2373-03fd-936f53f0b4b1
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-769745940
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
PDSH_RCMD_TYPE=ssh
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=3db4ece6-fe3f-499b-947e-5bb465738917
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=6p17d6XK-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Voluptuous-Dolore-Zy-Saisir-Ecke-Bedivere
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-4bbdc1cbe9.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=sub3,main1,sub1,sub2
BACKENDAI_SESSION_ID=da65926f-4510-4db9-a83f-aadcc30a1c79
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/usr/local/cuda-12.3/bin:/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/usr/local/cuda-12.3/bin:/usr/local/cuda-12.3/bin:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-c1e78f4a-a764-4e84-861a-e92b47cc6c84.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-d1b6c9f5-2fca-cc52-dfc9-c080dbd39f28,GPU-0a94f5ff-5681-0311-7df5-87b4c308ca95,GPU-d47aea79-b029-552f-addd-c9d6b4ac89a7,GPU-f5c55947-7ce9-2373-03fd-936f53f0b4b1
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-769745940
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
PDSH_RCMD_TYPE=ssh
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=3db4ece6-fe3f-499b-947e-5bb465738917
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=6p17d6XK-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Voluptuous-Dolore-Zy-Saisir-Ecke-Bedivere
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-4bbdc1cbe9.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=sub3,main1,sub1,sub2
BACKENDAI_SESSION_ID=da65926f-4510-4db9-a83f-aadcc30a1c79
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/usr/local/cuda-12.3/bin:/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/usr/local/cuda-12.3/bin:/usr/local/cuda-12.3/bin:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-c1e78f4a-a764-4e84-861a-e92b47cc6c84.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-d1b6c9f5-2fca-cc52-dfc9-c080dbd39f28,GPU-0a94f5ff-5681-0311-7df5-87b4c308ca95,GPU-d47aea79-b029-552f-addd-c9d6b4ac89a7,GPU-f5c55947-7ce9-2373-03fd-936f53f0b4b1
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-769745940
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
PDSH_RCMD_TYPE=ssh
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=3db4ece6-fe3f-499b-947e-5bb465738917
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=6p17d6XK-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Voluptuous-Dolore-Zy-Saisir-Ecke-Bedivere
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-4bbdc1cbe9.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/lib64:/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=sub3,main1,sub1,sub2
BACKENDAI_SESSION_ID=da65926f-4510-4db9-a83f-aadcc30a1c79
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/usr/local/cuda-12.3/bin:/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/usr/local/cuda-12.3/bin:/usr/local/cuda-12.3/bin:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-c1e78f4a-a764-4e84-861a-e92b47cc6c84.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-835651932
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-44bf9e72-67cb-484d-a05e-da6d8c873575.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-835651932
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-44bf9e72-67cb-484d-a05e-da6d8c873575.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-835651932
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-44bf9e72-67cb-484d-a05e-da6d8c873575.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-835651932
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
PDSH_RCMD_TYPE=ssh
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=4
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
CONDA_PREFIX_2=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_3=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-401462eb-627f-4345-b001-ac0318cecf20.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-835651932
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
PDSH_RCMD_TYPE=ssh
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=4
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
CONDA_PREFIX_2=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_3=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-401462eb-627f-4345-b001-ac0318cecf20.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-835651932
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
PDSH_RCMD_TYPE=ssh
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=4
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
CONDA_PREFIX_2=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_3=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-401462eb-627f-4345-b001-ac0318cecf20.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
LOCAL_USER_ID=1100
DALI_BUILD=11414174
PYTHONUNBUFFERED=1
BACKENDAI_CLUSTER_HOST=main1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-835651932
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
PDSH_RCMD_TYPE=ssh
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
TORCH_CUDNN_V8_API_ENABLED=1
NVM_DIR=/usr/local/nvm
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
TERM=xterm-256color
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=6
PIP_IGNORE_INSTALLED=0
SHLVL=4
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
JUPYTER_PORT=8888
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
CONDA_PREFIX_2=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_3=/home/work/channel/miniconda3
CONDA_PREFIX_4=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_5=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-401462eb-627f-4345-b001-ac0318cecf20.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
LOCAL_USER_ID=1100
DALI_BUILD=11414174
PYTHONUNBUFFERED=1
BACKENDAI_CLUSTER_HOST=main1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-835651932
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
PDSH_RCMD_TYPE=ssh
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
TORCH_CUDNN_V8_API_ENABLED=1
NVM_DIR=/usr/local/nvm
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
TERM=xterm-256color
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=6
PIP_IGNORE_INSTALLED=0
SHLVL=4
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
JUPYTER_PORT=8888
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
CONDA_PREFIX_2=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_3=/home/work/channel/miniconda3
CONDA_PREFIX_4=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_5=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-401462eb-627f-4345-b001-ac0318cecf20.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
LOCAL_USER_ID=1100
DALI_BUILD=11414174
PYTHONUNBUFFERED=1
BACKENDAI_CLUSTER_HOST=main1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-835651932
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
PDSH_RCMD_TYPE=ssh
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
TORCH_CUDNN_V8_API_ENABLED=1
NVM_DIR=/usr/local/nvm
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
TERM=xterm-256color
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=6
PIP_IGNORE_INSTALLED=0
SHLVL=4
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
JUPYTER_PORT=8888
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
CONDA_PREFIX_2=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_3=/home/work/channel/miniconda3
CONDA_PREFIX_4=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_5=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-401462eb-627f-4345-b001-ac0318cecf20.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
LOCAL_USER_ID=1100
DALI_BUILD=11414174
PYTHONUNBUFFERED=1
BACKENDAI_CLUSTER_HOST=main1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-835651932
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
PDSH_RCMD_TYPE=ssh
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
TORCH_CUDNN_V8_API_ENABLED=1
NVM_DIR=/usr/local/nvm
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
TERM=xterm-256color
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=6
PIP_IGNORE_INSTALLED=0
SHLVL=4
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
JUPYTER_PORT=8888
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
CONDA_PREFIX_2=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_3=/home/work/channel/miniconda3
CONDA_PREFIX_4=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_5=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-401462eb-627f-4345-b001-ac0318cecf20.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
LOCAL_USER_ID=1100
DALI_BUILD=11414174
PYTHONUNBUFFERED=1
BACKENDAI_CLUSTER_HOST=main1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-835651932
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
PDSH_RCMD_TYPE=ssh
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
TORCH_CUDNN_V8_API_ENABLED=1
NVM_DIR=/usr/local/nvm
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
TERM=xterm-256color
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=6
PIP_IGNORE_INSTALLED=0
SHLVL=4
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
JUPYTER_PORT=8888
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
CONDA_PREFIX_2=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_3=/home/work/channel/miniconda3
CONDA_PREFIX_4=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_5=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-401462eb-627f-4345-b001-ac0318cecf20.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
LOCAL_USER_ID=1100
DALI_BUILD=11414174
PYTHONUNBUFFERED=1
BACKENDAI_CLUSTER_HOST=main1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-835651932
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
PDSH_RCMD_TYPE=ssh
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
TORCH_CUDNN_V8_API_ENABLED=1
NVM_DIR=/usr/local/nvm
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
TERM=xterm-256color
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=6
PIP_IGNORE_INSTALLED=0
SHLVL=4
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
JUPYTER_PORT=8888
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
CONDA_PREFIX_2=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_3=/home/work/channel/miniconda3
CONDA_PREFIX_4=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_5=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-401462eb-627f-4345-b001-ac0318cecf20.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
LOCAL_USER_ID=1100
DALI_BUILD=11414174
PYTHONUNBUFFERED=1
BACKENDAI_CLUSTER_HOST=main1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-835651932
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
PDSH_RCMD_TYPE=ssh
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
TORCH_CUDNN_V8_API_ENABLED=1
NVM_DIR=/usr/local/nvm
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
TERM=xterm-256color
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=6
PIP_IGNORE_INSTALLED=0
SHLVL=4
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
JUPYTER_PORT=8888
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
CONDA_PREFIX_2=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_3=/home/work/channel/miniconda3
CONDA_PREFIX_4=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_5=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-401462eb-627f-4345-b001-ac0318cecf20.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
LOCAL_USER_ID=1100
DALI_BUILD=11414174
PYTHONUNBUFFERED=1
BACKENDAI_CLUSTER_HOST=main1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-835651932
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
PDSH_RCMD_TYPE=ssh
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
TORCH_CUDNN_V8_API_ENABLED=1
NVM_DIR=/usr/local/nvm
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
TERM=xterm-256color
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=6
PIP_IGNORE_INSTALLED=0
SHLVL=4
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
JUPYTER_PORT=8888
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
CONDA_PREFIX_2=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_3=/home/work/channel/miniconda3
CONDA_PREFIX_4=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_5=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-401462eb-627f-4345-b001-ac0318cecf20.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
LOCAL_USER_ID=1100
DALI_BUILD=11414174
PYTHONUNBUFFERED=1
BACKENDAI_CLUSTER_HOST=main1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-835651932
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
PDSH_RCMD_TYPE=ssh
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
TORCH_CUDNN_V8_API_ENABLED=1
NVM_DIR=/usr/local/nvm
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
TERM=xterm-256color
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=6
PIP_IGNORE_INSTALLED=0
SHLVL=4
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
JUPYTER_PORT=8888
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
CONDA_PREFIX_2=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_3=/home/work/channel/miniconda3
CONDA_PREFIX_4=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_5=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-401462eb-627f-4345-b001-ac0318cecf20.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
LOCAL_USER_ID=1100
DALI_BUILD=11414174
PYTHONUNBUFFERED=1
BACKENDAI_CLUSTER_HOST=main1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-835651932
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
PDSH_RCMD_TYPE=ssh
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
TORCH_CUDNN_V8_API_ENABLED=1
NVM_DIR=/usr/local/nvm
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
TERM=xterm-256color
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=6
PIP_IGNORE_INSTALLED=0
SHLVL=4
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
JUPYTER_PORT=8888
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
CONDA_PREFIX_2=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_3=/home/work/channel/miniconda3
CONDA_PREFIX_4=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_5=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-401462eb-627f-4345-b001-ac0318cecf20.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
LOCAL_USER_ID=1100
DALI_BUILD=11414174
PYTHONUNBUFFERED=1
BACKENDAI_CLUSTER_HOST=main1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-835651932
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
PDSH_RCMD_TYPE=ssh
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
TORCH_CUDNN_V8_API_ENABLED=1
NVM_DIR=/usr/local/nvm
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
TERM=xterm-256color
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=6
PIP_IGNORE_INSTALLED=0
SHLVL=4
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
JUPYTER_PORT=8888
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
CONDA_PREFIX_2=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_3=/home/work/channel/miniconda3
CONDA_PREFIX_4=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_5=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-401462eb-627f-4345-b001-ac0318cecf20.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
LOCAL_USER_ID=1100
DALI_BUILD=11414174
PYTHONUNBUFFERED=1
BACKENDAI_CLUSTER_HOST=main1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-835651932
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
PDSH_RCMD_TYPE=ssh
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
TORCH_CUDNN_V8_API_ENABLED=1
NVM_DIR=/usr/local/nvm
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
TERM=xterm-256color
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=6
PIP_IGNORE_INSTALLED=0
SHLVL=4
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
JUPYTER_PORT=8888
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
CONDA_PREFIX_2=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_3=/home/work/channel/miniconda3
CONDA_PREFIX_4=/home/work/channel/miniconda3/envs/dobby-parler
CONDA_PREFIX_5=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-401462eb-627f-4345-b001-ac0318cecf20.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-760050674
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-75cd20f3-a2c7-45bb-be09-3eaa14dedc34.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-760050674
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-75cd20f3-a2c7-45bb-be09-3eaa14dedc34.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-760050674
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-75cd20f3-a2c7-45bb-be09-3eaa14dedc34.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-760050674
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-75cd20f3-a2c7-45bb-be09-3eaa14dedc34.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-760050674
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-75cd20f3-a2c7-45bb-be09-3eaa14dedc34.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-760050674
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-75cd20f3-a2c7-45bb-be09-3eaa14dedc34.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-760050674
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-50953a6ed6.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-75cd20f3-a2c7-45bb-be09-3eaa14dedc34.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=3600
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=ERROR
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=DEBUG
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
NCCL_SHM_DISABLE=1
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=DEBUG
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
NCCL_SHM_DISABLE=1
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=DEBUG
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
NCCL_SHM_DISABLE=1
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=DEBUG
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
NCCL_SHM_DISABLE=1
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=DEBUG
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
NCCL_SHM_DISABLE=1
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=DEBUG
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
NCCL_SHM_DISABLE=1
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
NCCL_ASYNC_ERROR_HANDLING=1
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=DEBUG
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
NCCL_SHM_DISABLE=1
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
NCCL_ASYNC_ERROR_HANDLING=1
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=DEBUG
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
NCCL_SHM_DISABLE=1
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
NCCL_ASYNC_ERROR_HANDLING=1
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=DEBUG
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
NCCL_SHM_DISABLE=1
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
NCCL_ASYNC_ERROR_HANDLING=1
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=DEBUG
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
NCCL_SHM_DISABLE=1
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
NCCL_ASYNC_ERROR_HANDLING=1
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=DEBUG
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
NCCL_SHM_DISABLE=1
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
NCCL_ASYNC_ERROR_HANDLING=1
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=DEBUG
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
NCCL_SHM_DISABLE=1
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
NCCL_ASYNC_ERROR_HANDLING=1
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=DEBUG
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
NCCL_SHM_DISABLE=1
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
NCCL_ASYNC_ERROR_HANDLING=1
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=DEBUG
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
NCCL_SHM_DISABLE=1
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
NCCL_ASYNC_ERROR_HANDLING=1
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=DEBUG
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
NCCL_SHM_DISABLE=1
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
NCCL_ASYNC_ERROR_HANDLING=1
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=3
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-830863738
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-eeda2461-c422-4007-aa16-0e76668fcbd3.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
COLORTERM=truecolor
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
TERM_PROGRAM_VERSION=0.42.5
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/vscode-ssh-auth-sock-469017278
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
LOGNAME=work
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
VSCODE_GIT_ASKPASS_NODE=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/node
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
SSL_CERT_DIR=/usr/lib/ssl/certs
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
GIT_ASKPASS=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass.sh
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
USER=work
OPENMPI_VERSION=4.1.5rc2
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-4bbdc1cbe9.sock
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
TRANSFORMER_ENGINE_VERSION=1.2
LC_ALL=C.UTF-8
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
VSCODE_GIT_ASKPASS_MAIN=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/extensions/git/dist/askpass-main.js
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
BROWSER=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/helpers/browser.sh
PATH=/home/work/.cursor-server/cli/servers/Stable-001668006cc714afd397f4ef0d52862f5a095530/server/bin/remote-cli:/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS
TERM_PROGRAM=vscode
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-6a74dbda-3899-4015-89be-afffa4dc9d7f.sock
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/usr/bin/taskset
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=INFO
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NCCL_IB_HCA=mlx5_0
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
NCCL_IB_GID_INDEX=0
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NCCL_IB_SL=0
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=0
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
NPP_VERSION=12.2.3.2
SHELL=/bin/bash
BACKENDAI_ACCESS_KEY=AKIAMSNOSOJ575WHH753
NVIDIA_VISIBLE_DEVICES=GPU-70c18902-f1dc-e3da-970b-e33f2efe3ae8,GPU-ec6019ed-130d-9aad-1e83-ac75ee58d576,GPU-18f2c531-7b7a-7e57-6f8d-130a2a43e11a,GPU-c551a386-aea8-a841-de94-3e48c871049d
MLFLOW_EXPERIMENT_NAME=parler-tts-ko
DALI_BUILD=11414174
LOCAL_USER_ID=1100
BACKENDAI_CLUSTER_HOST=main1
PYTHONUNBUFFERED=1
CUSOLVER_VERSION=11.5.4.101
BACKENDAI_CLUSTER_IDX=1
CONDA_EXE=/home/work/channel/miniconda3/bin/conda
CUBLAS_VERSION=12.3.4.1
TMUX=/tmp//tmux-1100/default,15050,10
HOSTNAME=main1
CUFFT_VERSION=11.0.12.1
BNB_CUDA_VERSION=123
SSH_AUTH_SOCK=/tmp/ssh-XXXXXXbo7xo3/agent.55
CUDA_CACHE_DISABLE=1
TENSORBOARD_PORT=6006
SSH_AGENT_PID=56
NCCL_VERSION=2.19.4
NCCL_SOCKET_IFNAME=eth0
BACKENDAI_CLUSTER_SIZE=4
BACKENDAI_CLUSTER_LOCAL_RANK=0
CUSPARSE_VERSION=12.2.0.103
TF_MIN_GPU_MULTIPROCESSOR_COUNT=4
ENV=/etc/shinit_v2
BACKENDAI_CLUSTER_ROLE=main
PWD=/home/work/channel/dobby/TTS/modules/parler-tts
BACKENDAI_USER_UUID=b28ea1e1-d586-4641-8e2c-e9657afabb6f
CONDA_PREFIX=/home/work/channel/miniconda3/envs/dobby-parler
OPENUCX_VERSION=1.15.0
NSIGHT_SYSTEMS_VERSION=2023.4.1.97
BACKENDAI_KERNEL_ID=e5b98745-c047-4f55-abff-2749a30099b7
NVIDIA_DRIVER_CAPABILITIES=all
NCCL_P2P_LEVEL=NVL
POLYGRAPHY_VERSION=0.49.1
NCCL_DEBUG=DEBUG
BACKENDAI_SERVICE_PORTS=ipython:pty:3000,jupyter:http:8091,jupyterlab:http:8090,vscode:http:8180,tensorboard:http:6006,mlflow-ui:preopen:5000,nniboard:preopen:8080
LOCAL_GROUP_ID=1100
UCC_CL_BASIC_TLS=^sharp
TRT_VERSION=8.6.1.6+cuda12.0.1.011
BACKENDAI_CLUSTER_REPLICAS=main:1,sub:3
OPENBLAS_NUM_THREADS=1
NCCL_TIMEOUT=10000000
NVIDIA_PRODUCT_NAME=PyTorch
RDMACORE_VERSION=39.0
BACKENDAI_KERNEL_IMAGE=bai-repo:7080/bai/ngc-pytorch:24.01-pytorch2.2-py310-cuda12.3
LD_PRELOAD=/opt/kernel/libbaihook.so:/opt/kernel/libnvmlhook.ubuntu18.04.x86_64.so:/opt/kernel/libcudahook.ubuntu18.04.x86_64.so
HOME=/home/work
MLFLOW_TRACKING_URI=https://mlflow.exp.channel.io/
LANG=C.UTF-8
BACKENDAI_SESSION_NAME=NcVtq5Jn-session
BACKENDAI_USER_EMAIL=nipa-gpu2024-458@ktcloud.com
COCOAPI_VERSION=2.0+nv0.8.0
CUDA_VERSION=12.3.2.001
PYTORCH_VERSION=2.2.0a0+81ea7a4
CURAND_VERSION=10.3.4.107
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
PYTORCH_BUILD_NUMBER=0
USE_EXPERIMENTAL_CUDNN_V8_API=1
CUTENSOR_VERSION=2.0.0.7
PIP_DEFAULT_TIMEOUT=100
HPCX_VERSION=2.16rc4
NVM_DIR=/usr/local/nvm
TORCH_CUDNN_V8_API_ENABLED=1
PYTHONPATH=/home/work/.local/lib/python3.10/site-packages:/home/work/channel/dobby/TTS/modules/parler-tts
ALPHA_NUMERIC_VAL=Ro-Ihres-Twins-Rosina-Dinsmore-Disdains
TERM=xterm-256color
CPLUS_INCLUDE_PATH=/usr/include/gdal
GDRCOPY_VERSION=2.3
OPENMPI_VERSION=4.1.5rc2
TMUX_PANE=%10
NVJPEG_VERSION=12.3.0.81
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
PYTHONIOENCODING=utf-8
CONDA_SHLVL=2
PIP_IGNORE_INSTALLED=0
SHLVL=2
BASH_ENV=/etc/bash.bashrc
CUDNN_VERSION=8.9.7.29+cuda12.2
NSIGHT_COMPUTE_VERSION=2023.3.1.1
DALI_VERSION=1.33.0
BACKENDAI_USER_NAME=채널코퍼레이션
MPLBACKEND=Svg
JUPYTER_PORT=8888
CONDA_PYTHON_EXE=/home/work/channel/miniconda3/bin/python
PYTORCH_HOME=/opt/pytorch/pytorch
LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-12.3:/usr/local/cuda-12.3/include:/usr/include/x86_64-linux-gnu
NCCL_IB_DISABLE=1
NVIDIA_BUILD_ID=80741402
CONDA_DEFAULT_ENV=dobby-parler
OMPI_MCA_coll_hcoll_enable=0
BACKENDAI_CLUSTER_HOSTS=main1,sub1,sub2,sub3
BACKENDAI_SESSION_ID=faf2fcc8-f8f0-4e44-a913-71f026ab279d
OPAL_PREFIX=/opt/hpcx/ompi
OMP_NUM_THREADS=1
CUDA_DRIVER_VERSION=545.23.08
LC_ALL=C.UTF-8
TRANSFORMER_ENGINE_VERSION=1.2
PYTORCH_BUILD_VERSION=2.2.0a0+81ea7a4
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
OMPI_MCA_btl_tcp_if_exclude=127.0.0.1/32,10.63.0.64/26
PATH=/home/work/channel/miniconda3/envs/dobby-parler/bin:/home/work/channel/miniconda3/condabin:/home/work/.local/bin:/usr/local/cuda/bin:/usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
C_INCLUDE_PATH=/usr/include/gdal
MOFED_VERSION=5.4-rdmacore39.0
NVIDIA_PYTORCH_VERSION=24.01
TRTOSS_VERSION=23.11
CONDA_PREFIX_1=/home/work/channel/miniconda3
NCCL_CUDA_PATH=/opt/kernel
DEBIAN_FRONTEND=noninteractive
TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
NPROC=32
OLDPWD=/home/work/channel/dobby/TTS/modules
_=/home/work/channel/miniconda3/envs/dobby-parler/bin/accelerate
ACCELERATE_DEBUG_MODE=true
ACCELERATE_MIXED_PRECISION=no
ACCELERATE_CONFIG_DS_FIELDS=deepspeed_hostfile,deepspeed_multinode_launcher,deepspeed_config_file,zero3_init_flag
ACCELERATE_USE_DEEPSPEED=true
ACCELERATE_DEEPSPEED_ZERO3_INIT=false
ACCELERATE_DEEPSPEED_CONFIG_FILE=helpers/multinode/deepspeed_config_zero2.json
